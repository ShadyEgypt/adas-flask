{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import math\n",
    "import onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['direct', 'alternative']\n",
    "\n",
    "# Create a list of colors for each class where each color is a tuple of 3 integer values\n",
    "colors = [(65, 204, 123), (98, 137, 217)]\n",
    "\n",
    "\n",
    "def nms(boxes, scores, iou_threshold):\n",
    "    print(\"nms function from utils has been called\")\n",
    "    # Sort by score\n",
    "    sorted_indices = np.argsort(scores)[::-1]\n",
    "\n",
    "    keep_boxes = []\n",
    "    while sorted_indices.size > 0:\n",
    "        # Pick the last box\n",
    "        box_id = sorted_indices[0]\n",
    "        keep_boxes.append(box_id)\n",
    "\n",
    "        # Compute IoU of the picked box with the rest\n",
    "        ious = compute_iou(boxes[box_id, :], boxes[sorted_indices[1:], :])\n",
    "\n",
    "        # Remove boxes with IoU over the threshold\n",
    "        keep_indices = np.where(ious < iou_threshold)[0]\n",
    "\n",
    "        # print(keep_indices.shape, sorted_indices.shape)\n",
    "        sorted_indices = sorted_indices[keep_indices + 1]\n",
    "\n",
    "    return keep_boxes\n",
    "\n",
    "\n",
    "def compute_iou(box, boxes):\n",
    "    print(\"compute_iou function from utils has been called\")\n",
    "    # Compute xmin, ymin, xmax, ymax for both boxes\n",
    "    xmin = np.maximum(box[0], boxes[:, 0])\n",
    "    ymin = np.maximum(box[1], boxes[:, 1])\n",
    "    xmax = np.minimum(box[2], boxes[:, 2])\n",
    "    ymax = np.minimum(box[3], boxes[:, 3])\n",
    "\n",
    "    # Compute intersection area\n",
    "    intersection_area = np.maximum(0, xmax - xmin) * np.maximum(0, ymax - ymin)\n",
    "\n",
    "    # Compute union area\n",
    "    box_area = (box[2] - box[0]) * (box[3] - box[1])\n",
    "    boxes_area = (boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 1])\n",
    "    union_area = box_area + boxes_area - intersection_area\n",
    "\n",
    "    # Compute IoU\n",
    "    iou = intersection_area / union_area\n",
    "\n",
    "    return iou\n",
    "\n",
    "\n",
    "def xywh2xyxy(x):\n",
    "    print(\"xywh2xyxy function from utils has been called\")\n",
    "    # Convert bounding box (x, y, w, h) to bounding box (x1, y1, x2, y2)\n",
    "    y = np.copy(x)\n",
    "    y[..., 0] = x[..., 0] - x[..., 2] / 2\n",
    "    y[..., 1] = x[..., 1] - x[..., 3] / 2\n",
    "    y[..., 2] = x[..., 0] + x[..., 2] / 2\n",
    "    y[..., 3] = x[..., 1] + x[..., 3] / 2\n",
    "    return y\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    print(\"sigmoid function from utils has been called\")\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "def draw_detections(image, boxes, scores, class_ids, mask_alpha=0.3, mask_maps=None):\n",
    "    print(\"draw_detections function from utils has been called\")\n",
    "    img_height, img_width = image.shape[:2]\n",
    "    size = min([img_height, img_width]) * 0.0006\n",
    "    text_thickness = int(min([img_height, img_width]) * 0.001)\n",
    "\n",
    "    mask_img = draw_masks(image, boxes, class_ids, mask_alpha, mask_maps)\n",
    "\n",
    "    # Draw bounding boxes and labels of detections\n",
    "    for box, score, class_id in zip(boxes, scores, class_ids):\n",
    "        color = colors[class_id]\n",
    "\n",
    "        x1, y1, x2, y2 = box.astype(int)\n",
    "\n",
    "        # Draw rectangle\n",
    "        cv2.rectangle(mask_img, (x1, y1), (x2, y2), color, 2)\n",
    "\n",
    "        label = class_names[class_id]\n",
    "        caption = f'{label} {int(score * 100)}%'\n",
    "        (tw, th), _ = cv2.getTextSize(text=caption, fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                                      fontScale=size, thickness=text_thickness)\n",
    "        th = int(th * 1.2)\n",
    "\n",
    "        cv2.rectangle(mask_img, (x1, y1),\n",
    "                      (x1 + tw, y1 - th), color, -1)\n",
    "\n",
    "        cv2.putText(mask_img, caption, (x1, y1),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, size, (255, 255, 255), text_thickness, cv2.LINE_AA)\n",
    "\n",
    "    return mask_img\n",
    "\n",
    "\n",
    "def draw_masks(image, boxes, class_ids, mask_alpha=0.3, mask_maps=None):\n",
    "    print(\"draw_masks function from utils has been called\")\n",
    "    mask_img = image.copy()\n",
    "\n",
    "    # Draw bounding boxes and labels of detections\n",
    "    for i, (box, class_id) in enumerate(zip(boxes, class_ids)):\n",
    "        color = colors[class_id]\n",
    "\n",
    "        x1, y1, x2, y2 = box.astype(int)\n",
    "\n",
    "        # Draw fill mask image\n",
    "        if mask_maps is None:\n",
    "            cv2.rectangle(mask_img, (x1, y1), (x2, y2), color, -1)\n",
    "        else:\n",
    "            crop_mask = mask_maps[i][y1:y2, x1:x2, np.newaxis]\n",
    "            crop_mask_img = mask_img[y1:y2, x1:x2]\n",
    "            crop_mask_img = crop_mask_img * (1 - crop_mask) + crop_mask * color\n",
    "            mask_img[y1:y2, x1:x2] = crop_mask_img\n",
    "\n",
    "    return cv2.addWeighted(mask_img, mask_alpha, image, 1 - mask_alpha, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLOv8_Segmentation_Model:\n",
    "\n",
    "    def __init__(self, path, conf_thres=0.7, iou_thres=0.5, num_masks=32):\n",
    "        print(\"__init__ function from the class has been called\")\n",
    "        self.conf_threshold = conf_thres\n",
    "        self.iou_threshold = iou_thres\n",
    "        self.num_masks = num_masks\n",
    "\n",
    "        # Initialize model\n",
    "        self.initialize_model(path)\n",
    "\n",
    "    def __call__(self, image):\n",
    "        print(\"__call__ function from the class has been called\")\n",
    "        return self.segment_objects(image)\n",
    "\n",
    "    def initialize_model(self, path):\n",
    "        print(\"initialize_model function from the class has been called\")\n",
    "        self.session = onnxruntime.InferenceSession(path,\n",
    "                                                    providers=['CUDAExecutionProvider',\n",
    "                                                               'CPUExecutionProvider'])\n",
    "        # Get model info\n",
    "        self.get_input_details()\n",
    "        self.get_output_details()\n",
    "\n",
    "    def segment_objects(self, image):\n",
    "        print(\"segment_objects function from the class has been called\")\n",
    "        input_tensor = self.prepare_input(image)\n",
    "\n",
    "        # Perform inference on the image\n",
    "        outputs = self.inference(input_tensor)\n",
    "\n",
    "        self.boxes, self.scores, self.class_ids, mask_pred = self.process_box_output(outputs[0])\n",
    "        self.mask_maps = self.process_mask_output(mask_pred, outputs[1])\n",
    "\n",
    "        return self.boxes, self.scores, self.class_ids, self.mask_maps\n",
    "\n",
    "    def prepare_input(self, image):\n",
    "        print(\"prepare_input function from the class has been called\")\n",
    "        self.img_height, self.img_width, _ = image.shape\n",
    "\n",
    "        input_img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Resize input image\n",
    "        input_img = cv2.resize(input_img, (self.input_width, self.input_height))\n",
    "\n",
    "        # Scale input pixel values to 0 to 1\n",
    "        input_img = input_img / 255.0\n",
    "        input_img = input_img.transpose(2, 0, 1)\n",
    "        input_tensor = input_img[np.newaxis, :, :, :].astype(np.float32)\n",
    "\n",
    "        return input_tensor\n",
    "\n",
    "    def inference(self, input_tensor):\n",
    "        print(\"inference function from the class has been called\")\n",
    "        start = time.perf_counter()\n",
    "        outputs = self.session.run(self.output_names, {self.input_names[0]: input_tensor})\n",
    "\n",
    "        # print(f\"Inference time: {(time.perf_counter() - start)*1000:.2f} ms\")\n",
    "        return outputs\n",
    "\n",
    "    def process_box_output(self, box_output):\n",
    "        print(\"process_box_output function from the class has been called\")\n",
    "        predictions = np.squeeze(box_output).T\n",
    "        num_classes = box_output.shape[1] - self.num_masks - 4\n",
    "\n",
    "        # Filter out object confidence scores below threshold\n",
    "        scores = np.max(predictions[:, 4:4+num_classes], axis=1)\n",
    "        predictions = predictions[scores > self.conf_threshold, :]\n",
    "        scores = scores[scores > self.conf_threshold]\n",
    "\n",
    "        if len(scores) == 0:\n",
    "            return [], [], [], np.array([])\n",
    "\n",
    "        box_predictions = predictions[..., :num_classes+4]\n",
    "        mask_predictions = predictions[..., num_classes+4:]\n",
    "\n",
    "        # Get the class with the highest confidence\n",
    "        class_ids = np.argmax(box_predictions[:, 4:], axis=1)\n",
    "\n",
    "        # Get bounding boxes for each object\n",
    "        boxes = self.extract_boxes(box_predictions)\n",
    "\n",
    "        # Apply non-maxima suppression to suppress weak, overlapping bounding boxes\n",
    "        indices = nms(boxes, scores, self.iou_threshold)\n",
    "\n",
    "        return boxes[indices], scores[indices], class_ids[indices], mask_predictions[indices]\n",
    "\n",
    "    def process_mask_output(self, mask_predictions, mask_output):\n",
    "        print(\"process_mask_output function from the class has been called\")\n",
    "        if mask_predictions.shape[0] == 0:\n",
    "            return []\n",
    "\n",
    "        mask_output = np.squeeze(mask_output)\n",
    "\n",
    "        # Calculate the mask maps for each box\n",
    "        num_mask, mask_height, mask_width = mask_output.shape  # CHW\n",
    "        masks = sigmoid(mask_predictions @ mask_output.reshape((num_mask, -1)))\n",
    "        masks = masks.reshape((-1, mask_height, mask_width))\n",
    "\n",
    "        # Downscale the boxes to match the mask size\n",
    "        scale_boxes = self.rescale_boxes(self.boxes,\n",
    "                                   (self.img_height, self.img_width),\n",
    "                                   (mask_height, mask_width))\n",
    "\n",
    "        # For every box/mask pair, get the mask map\n",
    "        mask_maps = np.zeros((len(scale_boxes), self.img_height, self.img_width))\n",
    "        blur_size = (int(self.img_width / mask_width), int(self.img_height / mask_height))\n",
    "        for i in range(len(scale_boxes)):\n",
    "\n",
    "            scale_x1 = int(math.floor(scale_boxes[i][0]))\n",
    "            scale_y1 = int(math.floor(scale_boxes[i][1]))\n",
    "            scale_x2 = int(math.ceil(scale_boxes[i][2]))\n",
    "            scale_y2 = int(math.ceil(scale_boxes[i][3]))\n",
    "\n",
    "            x1 = int(math.floor(self.boxes[i][0]))\n",
    "            y1 = int(math.floor(self.boxes[i][1]))\n",
    "            x2 = int(math.ceil(self.boxes[i][2]))\n",
    "            y2 = int(math.ceil(self.boxes[i][3]))\n",
    "\n",
    "            scale_crop_mask = masks[i][scale_y1:scale_y2, scale_x1:scale_x2]\n",
    "            crop_mask = cv2.resize(scale_crop_mask,\n",
    "                              (x2 - x1, y2 - y1),\n",
    "                              interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "            crop_mask = cv2.blur(crop_mask, blur_size)\n",
    "\n",
    "            crop_mask = (crop_mask > 0.5).astype(np.uint8)\n",
    "            mask_maps[i, y1:y2, x1:x2] = crop_mask\n",
    "\n",
    "        return mask_maps\n",
    "\n",
    "    def extract_boxes(self, box_predictions):\n",
    "        print(\"extract_boxes function from the class has been called\")\n",
    "        # Extract boxes from predictions\n",
    "        boxes = box_predictions[:, :4]\n",
    "\n",
    "        # Scale boxes to original image dimensions\n",
    "        boxes = self.rescale_boxes(boxes,\n",
    "                                   (self.input_height, self.input_width),\n",
    "                                   (self.img_height, self.img_width))\n",
    "\n",
    "        # Convert boxes to xyxy format\n",
    "        boxes = xywh2xyxy(boxes)\n",
    "\n",
    "        # Check the boxes are within the image\n",
    "        boxes[:, 0] = np.clip(boxes[:, 0], 0, self.img_width)\n",
    "        boxes[:, 1] = np.clip(boxes[:, 1], 0, self.img_height)\n",
    "        boxes[:, 2] = np.clip(boxes[:, 2], 0, self.img_width)\n",
    "        boxes[:, 3] = np.clip(boxes[:, 3], 0, self.img_height)\n",
    "\n",
    "        return boxes\n",
    "\n",
    "    def draw_detections(self, image, draw_scores=True, mask_alpha=0.4):\n",
    "        print(\"draw_detections function from the class has been called\")\n",
    "        return draw_detections(image, self.boxes, self.scores,\n",
    "                               self.class_ids, mask_alpha)\n",
    "\n",
    "    def draw_masks(self, image, draw_scores=True, mask_alpha=0.5):\n",
    "        print(\"draw_masks function from the class has been called\")\n",
    "        return draw_detections(image, self.boxes, self.scores,\n",
    "                               self.class_ids, mask_alpha, mask_maps=self.mask_maps)\n",
    "\n",
    "    def get_input_details(self):\n",
    "        print(\"get_input_details function from the class has been called\")\n",
    "        model_inputs = self.session.get_inputs()\n",
    "        self.input_names = [model_inputs[i].name for i in range(len(model_inputs))]\n",
    "\n",
    "        self.input_shape = model_inputs[0].shape\n",
    "        self.input_height = self.input_shape[2]\n",
    "        self.input_width = self.input_shape[3]\n",
    "\n",
    "    def get_output_details(self):\n",
    "        print(\"get_output_details function from the class has been called\")\n",
    "        model_outputs = self.session.get_outputs()\n",
    "        self.output_names = [model_outputs[i].name for i in range(len(model_outputs))]\n",
    "\n",
    "    @staticmethod\n",
    "    def rescale_boxes(boxes, input_shape, image_shape):\n",
    "        print(\"rescale_boxes function from the class has been called\")\n",
    "        # Rescale boxes to original image dimensions\n",
    "        input_shape = np.array([input_shape[1], input_shape[0], input_shape[1], input_shape[0]])\n",
    "        boxes = np.divide(boxes, input_shape, dtype=np.float32)\n",
    "        boxes *= np.array([image_shape[1], image_shape[0], image_shape[1], image_shape[0]])\n",
    "\n",
    "        return boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__init__ function from the class has been called\n",
      "initialize_model function from the class has been called\n",
      "get_input_details function from the class has been called\n",
      "get_output_details function from the class has been called\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shady/anaconda3/envs/myenv/lib/python3.11/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:69: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_path = \"model/best.onnx\"\n",
    "model = YOLOv8_Segmentation_Model(model_path, conf_thres=0.5, iou_thres=0.3)\n",
    "img_file_path = './data/d3f34243-a7166713.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(img_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__call__ function from the class has been called\n",
      "segment_objects function from the class has been called\n",
      "prepare_input function from the class has been called\n",
      "inference function from the class has been called\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process_box_output function from the class has been called\n",
      "extract_boxes function from the class has been called\n",
      "rescale_boxes function from the class has been called\n",
      "xywh2xyxy function from utils has been called\n",
      "nms function from utils has been called\n",
      "compute_iou function from utils has been called\n",
      "compute_iou function from utils has been called\n",
      "process_mask_output function from the class has been called\n",
      "sigmoid function from utils has been called\n",
      "rescale_boxes function from the class has been called\n",
      "draw_masks function from the class has been called\n",
      "draw_detections function from utils has been called\n",
      "draw_masks function from utils has been called\n"
     ]
    }
   ],
   "source": [
    "boxes, scores, class_ids, masks = model(img)\n",
    "output_image = model.draw_masks(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('./result.jpg', output_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
